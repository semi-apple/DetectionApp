{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60967c0b",
   "metadata": {},
   "source": [
    "<span style=\"color: blue\">Note: This notebooks is written on VsCode, the layout on Pycharm and VsCode may be different.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b22b09d2af6c123e",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Analyze Training Results\n",
    "During this phase, I trained four models (yolo8s-seg.pt, yolov8m-seg.pt, yolov8s-p2.pt and yolov8m-p2.pt), yolov8l and yolov8x series are too large to train (training time is longer than 15 hours). Here are the results of these model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e8ca9358038f030",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Table 1 - model: yolov8s-seg, epochs: 155, running time: 9.176h\n",
    "| Class | Images | Instances | Box(P) | Box(R) | mAP50(B) | mAP50-95(B) | Mask(P) | Mask(R) | mAP50(M) | mAP50-95(M) |\n",
    "| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |\n",
    "| all | 28 | 389 | 0.431 | 0.269 | 0.259 | 0.131 | 0.365 | 0.237 | 0.212 | 0.082 | \n",
    "| scratch | 18 | 79 | 0.42 | 0.294 | 0.26 | 0.155 | 0.34 | 0.318 | 0.22\t| 0.093 |\n",
    "| stain | 22 | 310 | 0.443 | 0.245 | 0.259 | 0.107 | 0.387 | 0.159 | 0.213 | 0.073 | "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7630c1754fdc2f5",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Table 2 - model: yolov8m-seg, epochs:284, running time: 15.774\n",
    "\n",
    "| Class | Images | Instances | Box(P) | Box(R) | mAP50(B) | mAP50-95(B) | Mask(P) | Mask(R) | mAP50(M) | mAP50-95(M) |\n",
    "| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |\n",
    "| all | 28 | 389 | 0.4 | 0.271 | 0.271 | 0.138 | 0.46 | 0.187 | 0.222 | 0.0946 |\n",
    "| scratch | 18 | 79 | 0.382 | 0.329 | 0.29 | 0.174 | 0.433 | 0.215 | 0.231 | 0.116 |\n",
    "| stain | 22 | 310 | 0.419 | 0.213 | 0.252 | 0.103 | 0.486 | 0.159 | 0.213 | 0.073 | "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e7106802f958ce3",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Table 3 - model: yolov8s-p2, epochs:146, running time: 9.147\n",
    "| Class | Images | Instances | Box(P) | Box(R) | mAP50(B) | mAP50-95(B) |\n",
    "| --- | --- | --- | --- | --- | --- | --- |\n",
    "| all | 28 | 389 | 0.38 | 0.262 | 0.249 | 0.12 | \n",
    "| scratch | 18 | 79 | 0.341 | 0.291 | 0.251 | 0.15 | \n",
    "| stain | 22 | 310 | 0.419 | 0.232 | 0.247 | 0.0896 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e4593bcc0299f6",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Table 4 - model: yolov8m-p2, epochs:218, running time: 8.251\n",
    "| Class | Images | Instances | Box(P) | Box(R) | mAP50(B) | mAP50-95(B) |\n",
    "| --- | --- | --- | --- | --- | --- | --- |\n",
    "| all | 28 | 389 | 0.378 | 0.323 | 0.271 | 0.135 | \n",
    "| scratch | 18 | 79 | 0.287 | 0.405 | 0.302 | 0.176 | \n",
    "| stain | 22 | 310 | 0.47 | 0.242 | 0.241 | 0.0943  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d9691dbce53b5f",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "<p style=\"line-height: 150%;\">Note that two computers were used to train models (one is from Viraj the other is from the uni laboratory) so the training time may vary. I also trained those model with preprocessing (tile), but the results were not very good (training result with 'tile' string, i.e., 'model: yolov8s-seg, epochs:209, running time: 10.091, tile: 3*3')\n",
    "P2 model (like yolov8m-p2) does not have segmentation mode, so there is no segmentation parameters in the result (i.e., mAP50(M), 'M' for mask). </p>\n",
    "\n",
    "<p style=\"line-height: 150%;\">There are two dataset version, the results were generated by modified version, (with only 'strain' and 'scratch' classes in dataset). Before that, there were 'chip', 'dent', 'missing', 'scratch' and 'stain'. Dataset was modified since 'missing' and 'dent' lack of instances, 'chip' and 'scratch' quite the same, resulting in bad result. </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd83313",
   "metadata": {},
   "source": [
    "## Use Cocoeval to analyze models\n",
    "<p style=\"line-height: 150%;\">Sahi does not support preprocessing, which means we cannot use YOLO's traning result to measure preformance. Instead, we can analyze models using <i>cocoeval</i>, a tool to analyze coco dataset (JSON format). By doing so, we need to transfer our dataset from yolo format to coco format, simply select coco format on <i>RoboFlow</i>. </p>\n",
    "\n",
    "<img src=\"images/select_coco_dataset.png\" alt=\"select coco dataset\" title=\"select coco dataset\" style=\"width:600px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db917c44",
   "metadata": {},
   "source": [
    "<p style=\"line-height: 150%;\">Usually we need to modify annotation file after downloading since the class number of object in coco dataset starts on 1 rather than 0 on YOLO. Can simply modify categories in <i>_annotation.json</i> file to match class numbers. </p>\n",
    "\n",
    "```json    \n",
    "\"categories\": [\n",
    "    {\n",
    "        \"id\": 0,\n",
    "        \"name\": \"scratch\",\n",
    "        \"supercategory\": \"defects-pbH2\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": 1,\n",
    "        \"name\": \"stain\",\n",
    "        \"supercategory\": \"defects-pbH2\"\n",
    "    }\n",
    "],\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "130a2d73",
   "metadata": {},
   "source": [
    "## Install Dependencies\n",
    "Then we can start to analyze small objects on dataset. First install dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59123502",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sahi\n",
    "!pip install pycocotools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e72345",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "from pycocotools.cocoeval import COCOeval\n",
    "from pycocotools.coco import COCO\n",
    "\n",
    "from sahi import AutoDetectionModel\n",
    "from sahi.predict import predict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e550e69",
   "metadata": {},
   "source": [
    "The dataset is splited into three (train, val and test), we can only use test set to analyze."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f230fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "dir_path = os.getcwd()\n",
    "image_dir = os.path.join(dir_path, 'cocodataset/test')\n",
    "coco_json_path = os.path.join(image_dir, '_annotations.coco.json')\n",
    "model_dir_path = os.path.join(dir_path, '/training_results/')\n",
    "m_p2 = 'm-p2/train2/weights/best.pt'\n",
    "s_p2 = 'yolov8s-p2/train/weights/best.pt'\n",
    "m_seg = 'm-seg/train3/weights/best.pt'\n",
    "s_seg = 's-seg/train2/weights/best.pt'\n",
    "\n",
    "# export result\n",
    "no_sahi_path = 'runs/no_sahi'\n",
    "sahi_2_2_path = 'runs/2_2'\n",
    "sahi_3_3_path = 'runs/3_3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ffc454",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define parameters, note that original image size is 1920*1080\n",
    "# slice_height = 420\n",
    "# slice_width = 740\n",
    "overlap_height_ratio = 0.2\n",
    "overlap_width_ratio = 0.2\n",
    "h, w = 1080, 1920\n",
    "prediction_times = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "096ff245",
   "metadata": {},
   "outputs": [],
   "source": [
    "# slice num is the number of silce of each edge, i.e., 2 for 2*2 slices.\n",
    "def analyze_model(model_path, slice_num, export_json_path): \n",
    "    detection_model = AutoDetectionModel.from_pretrained(\n",
    "        model_type='yolov8',\n",
    "        model_path=model_path,\n",
    "        confidence_threshold=0.3,\n",
    "        device=\"cuda\"  # or \"cpu\"\n",
    "    )\n",
    "    \n",
    "    W = slice_num - 0.2 * (slice_num - 1)\n",
    "\n",
    "    start_time = time.time()\n",
    "    coco_result = predict(\n",
    "        detection_model=detection_model,\n",
    "        source=image_dir,\n",
    "        slice_height=int(h / W),\n",
    "        slice_width=int(w / W),\n",
    "        overlap_height_ratio=overlap_height_ratio,\n",
    "        overlap_width_ratio=overlap_width_ratio,\n",
    "        project=sahi_3_3_path,\n",
    "        name=\"exp\",\n",
    "        export_coco=True,\n",
    "        dataset_json_path=coco_json_path\n",
    "    )\n",
    "    \n",
    "    if os.path.exists(export_json_path):\n",
    "        print(f\"Prediction results exported successfully to {export_json_path}\")\n",
    "    else:\n",
    "        print(f\"Error: {export_json_path} not found!\")\n",
    "\n",
    "    coco_gt = COCO(coco_json_path)\n",
    "    coco_pred = coco_gt.loadRes(export_json_path)\n",
    "\n",
    "    # TP, FP, FN = calculate_tp_fp_fn(coco_gt, coco_pred, iou_threshold=0.3)\n",
    "    # print(f\"TP: {TP}, FP: {FP}, FN: {FN}\")\n",
    "    coco_eval = COCOeval(coco_gt, coco_pred, iouType=\"bbox\") # can change iouType to 'segm' if segmentation mode needed\n",
    "    coco_eval.evaluate()\n",
    "    coco_eval.accumulate()\n",
    "    coco_eval.summarize()\n",
    "\n",
    "    total_detections = len(coco_pred.getAnnIds())\n",
    "    print(f\"Number of detected objects: {total_detections}\")\n",
    "\n",
    "    tp = coco_eval.eval['precision'][0, :, :, 0, 2]  # IoU=0.5, area=all, maxDet=100\n",
    "    true_positives = int(tp.sum())\n",
    "    print(f\"Number of TP: {true_positives}\")\n",
    "\n",
    "    false_positives = total_detections - true_positives\n",
    "    false_negatives = len(coco_gt.getAnnIds()) - true_positives\n",
    "    print(f\"Number of FP: {false_positives}\")\n",
    "    print(f\"Number of FN: {false_negatives}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3525cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reanalyze if missed up (evaluation results already exists)\n",
    "def reanalyze(export_json_path):\n",
    "    coco_gt = COCO(coco_json_path)\n",
    "    coco_pred = coco_gt.loadRes(export_json_path)\n",
    "\n",
    "    # TP, FP, FN = calculate_tp_fp_fn(coco_gt, coco_pred, iou_threshold=0.3)\n",
    "    # print(f\"TP: {TP}, FP: {FP}, FN: {FN}\")\n",
    "    coco_eval = COCOeval(coco_gt, coco_pred, iouType=\"bbox\")\n",
    "    coco_eval.evaluate()\n",
    "    coco_eval.accumulate()\n",
    "    coco_eval.summarize()\n",
    "\n",
    "    total_detections = len(coco_pred.getAnnIds())\n",
    "    print(f\"Number of detected objects: {total_detections}\")\n",
    "\n",
    "    tp = coco_eval.eval['precision'][0, :, :, 0, 2]  # IoU=0.5, area=all, maxDet=100\n",
    "    true_positives = int(tp.sum())\n",
    "    print(f\"Number of TP: {true_positives}\")\n",
    "\n",
    "    false_positives = total_detections - true_positives\n",
    "    false_negatives = len(coco_gt.getAnnIds()) - true_positives\n",
    "    print(f\"Number of FP: {false_positives}\")\n",
    "    print(f\"Number of FN: {false_negatives}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e90822fd",
   "metadata": {},
   "source": [
    "Calculate average inference time based on the evaluation results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e4631ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_text = \"\"\"\n",
    "Performing prediction on 9 slices.                                                 \n",
    "Prediction time is: 1604.85 ms                                                     \n",
    "Performing prediction on 9 slices.                                                 \n",
    "Prediction time is: 613.62 ms                                                      \n",
    "Performing prediction on 9 slices.                                                 \n",
    "Prediction time is: 467.03 ms                                                      \n",
    "Performing prediction on 9 slices.                                                 \n",
    "Prediction time is: 492.12 ms                                                      \n",
    "Performing prediction on 9 slices.                                                 \n",
    "Prediction time is: 540.01 ms                                                      \n",
    "Performing prediction on 9 slices.                                                 \n",
    "Prediction time is: 474.16 ms                                                      \n",
    "Performing prediction on 12 slices.                                                \n",
    "Prediction time is: 617.48 ms                                                      \n",
    "Performing prediction on 9 slices.                                                 \n",
    "Prediction time is: 584.09 ms                                                      \n",
    "Performing prediction on 12 slices.                                                \n",
    "Prediction time is: 612.03 ms                                                      \n",
    "Performing prediction on 9 slices.                                                 \n",
    "Prediction time is: 504.72 ms                                                      \n",
    "Performing prediction on 9 slices.                                                 \n",
    "Prediction time is: 502.49 ms                                                      \n",
    "Performing prediction on 12 slices.                                                \n",
    "Prediction time is: 687.79 ms                                                      \n",
    "Performing prediction on 9 slices.                                                 \n",
    "Prediction time is: 518.58 ms                                                      \n",
    "Performing prediction on 9 slices.                                                 \n",
    "Prediction time is: 512.17 ms                                                      \n",
    "Performing prediction on 9 slices.                                                 \n",
    "Prediction time is: 457.43 ms                                                      \n",
    "Performing prediction on 9 slices.                                                 \n",
    "Prediction time is: 648.55 ms                                                      \n",
    "Performing prediction on 9 slices.                                                 \n",
    "Prediction time is: 667.46 ms                                                      \n",
    "Performing prediction on 9 slices.                                                 \n",
    "Prediction time is: 482.98 ms                                                      \n",
    "Performing prediction on 9 slices.                                                 \n",
    "Prediction time is: 476.35 ms                                                      \n",
    "Performing prediction on 9 slices.                                                 \n",
    "Prediction time is: 512.53 ms                                                      \n",
    "Performing prediction on 9 slices.                                                 \n",
    "Prediction time is: 606.90 ms                                                      \n",
    "Performing prediction on 9 slices.                                                 \n",
    "Prediction time is: 737.83 ms  \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ce5a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def extract_times_and_calculate_average(log_text):\n",
    "    time_pattern = r\"Prediction time is: (\\d+\\.\\d+) ms\"\n",
    "    times = re.findall(time_pattern, log_text)\n",
    "\n",
    "    prediction_times = [float(time) for time in times]\n",
    "    \n",
    "    if prediction_times:\n",
    "        average_time = sum(prediction_times) / len(prediction_times)\n",
    "        return average_time\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "average_time = extract_times_and_calculate_average(log_text)\n",
    "print(f'Average time: {average_time:.2f} ms')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f12ab555",
   "metadata": {},
   "source": [
    "We can start with yolov8m-seg model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1417808",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = os.path.join(model_dir_path, m_seg)\n",
    "\n",
    "# assume using 2*2 slices\n",
    "export_dir_path = os.path.join(dir_path, sahi_2_2_path)\n",
    "export_json_path = os.path.join(export_dir_path, \"exp/result.json\")\n",
    "\n",
    "analyze_model(model_path=model_path, slice_num=2, export_json_path=export_json_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f7f260",
   "metadata": {},
   "source": [
    "For example, the result:\n",
    "\n",
    "### COCO Evaluation Metrics\n",
    "\n",
    "| Metric               | IoU Threshold   | Area    | Max Detections | Value  |\n",
    "|-----------------------|-----------------|---------|----------------|--------|\n",
    "| Average Precision (AP)| 0.50:0.95      | all     | 100            | 0.065  |\n",
    "| Average Precision (AP)| 0.50           | all     | 100            | 0.185  |\n",
    "| Average Precision (AP)| 0.75           | all     | 100            | 0.046  |\n",
    "| Average Precision (AP)| 0.50:0.95      | small   | 100            | 0.012  |\n",
    "| Average Precision (AP)| 0.50:0.95      | medium  | 100            | 0.300  |\n",
    "| Average Precision (AP)| 0.50:0.95      | large   | 100            | 0.430  |\n",
    "| Average Recall (AR)   | 0.50:0.95      | all     | 1              | 0.027  |\n",
    "| Average Recall (AR)   | 0.50:0.95      | all     | 10             | 0.091  |\n",
    "| Average Recall (AR)   | 0.50:0.95      | all     | 100            | 0.103  |\n",
    "| Average Recall (AR)   | 0.50:0.95      | small   | 100            | 0.038  |\n",
    "| Average Recall (AR)   | 0.50:0.95      | medium  | 100            | 0.402  |\n",
    "| Average Recall (AR)   | 0.50:0.95      | large   | 100            | 0.477  |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c910d509",
   "metadata": {},
   "source": [
    "### Confusion Matrix and Inference Time\n",
    "| Number of detected objects | Number of TP | Number of FP | Number of FN | Average time |\n",
    "|----------------------------|--------------|--------------|--------------|--------------|\n",
    "| 379 | 37 | 342 | 338 | 446.76ms |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
